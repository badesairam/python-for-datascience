{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction\n",
    "    It involves processing a document into sentences and each sentence is further subdivided into words and then used to identify a named entities in each sentence and finally we use relation recognition to search for likelu relations between different entities in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns Parsed :: (S\n",
      "  (NP The/DT quick/JJ brown/NN)\n",
      "  (NP fox/NN)\n",
      "  jumped/VBD\n",
      "  over/IN\n",
      "  (NP the/DT lazy/JJ dog/NN)\n",
      "  and/CC\n",
      "  easily/RB\n",
      "  killed/VBD\n",
      "  it/PRP)\n",
      "(NP The/DT quick/JJ brown/NN)\n",
      "(NP fox/NN)\n",
      "(NP the/DT lazy/JJ dog/NN)\n"
     ]
    }
   ],
   "source": [
    "import nltk,re\n",
    "#a preprocess which tokenizes a document and then does part of speech tagging for each word\n",
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences\n",
    "\n",
    "text = nltk.word_tokenize(\"The quick brown fox jumped over the lazy dog and easily killed it\")\n",
    "text = nltk.pos_tag(text)\n",
    "#chunker \n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\" #grammar for identifying NP chunks\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(text)\n",
    "# result.draw()\n",
    "print(\"Nouns Parsed ::\", result)\n",
    "for subtree in result.subtrees():\n",
    "    if subtree.label() == 'NP':\n",
    "        print(subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (GPE U.S./NNP)\n",
      "  is/VBZ\n",
      "  one/CD\n",
      "  of/IN\n",
      "  the/DT\n",
      "  few/JJ\n",
      "  industrialized/VBN\n",
      "  nations/NNS\n",
      "  that/WDT\n",
      "  *T*-7/-NONE-\n",
      "  does/VBZ\n",
      "  n't/RB\n",
      "  have/VB\n",
      "  a/DT\n",
      "  higher/JJR\n",
      "  standard/NN\n",
      "  of/IN\n",
      "  regulation/NN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  smooth/JJ\n",
      "  ,/,\n",
      "  needle-like/JJ\n",
      "  fibers/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  crocidolite/NN\n",
      "  that/WDT\n",
      "  *T*-1/-NONE-\n",
      "  are/VBP\n",
      "  classified/VBN\n",
      "  *-5/-NONE-\n",
      "  as/IN\n",
      "  amphobiles/NNS\n",
      "  ,/,\n",
      "  according/VBG\n",
      "  to/TO\n",
      "  (PERSON Brooke/NNP T./NNP Mossman/NNP)\n",
      "  ,/,\n",
      "  a/DT\n",
      "  professor/NN\n",
      "  of/IN\n",
      "  pathlogy/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION University/NNP)\n",
      "  of/IN\n",
      "  (PERSON Vermont/NNP College/NNP)\n",
      "  of/IN\n",
      "  (GPE Medicine/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('treebank')\n",
    "# sent = nltk.corpus.brown.tagged_sents(categories='news')[20]\n",
    "# print(sent)\n",
    "sent = nltk.corpus.treebank.tagged_sents()[22]\n",
    "# print(sent)\n",
    "print(nltk.ne_chunk(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
